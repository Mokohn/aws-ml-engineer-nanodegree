{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87bee315",
   "metadata": {},
   "source": [
    "# UDACITY SageMaker Essentials: Processing Job Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507f42f",
   "metadata": {},
   "source": [
    "In prior exercises, we've been running and rerunning the same preprocessing job over and over again. For cleanly formatted data, it's possible to do some preprocessing utilizing batch transform. However, if slightly more sophisticated processing is needed, we would want to do so through a processing job. Finally, after beating around the bush for a few exercises, we're finally going offload the preprocessing step of our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6243dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01bfd80",
   "metadata": {},
   "source": [
    "## Preprocessing (for the final time!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9f700",
   "metadata": {},
   "source": [
    "The cell below should be very familiar to you by now. This cell will write the preprocessing code to a file called \"HelloBlazePreprocess.py\". This code will be utilized by AWS via a SciKitLearn processing interface to process our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744a4a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting HelloBlazePreprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile HelloBlazePreprocess.py\n",
    "\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "# Function below unzips the archive to the local directory. \n",
    "\n",
    "def unzip_data(input_data_path):\n",
    "    with zipfile.ZipFile(input_data_path, 'r') as input_data_zip:\n",
    "        input_data_zip.extractall('./data/')\n",
    "        return input_data_zip.namelist()[0]\n",
    "\n",
    "# Input data is a file with a single JSON object per line with the following format: \n",
    "# {\n",
    "#  \"reviewerID\": <string>,\n",
    "#  \"asin\": <string>,\n",
    "#  \"reviewerName\" <string>,\n",
    "#  \"helpful\": [\n",
    "#    <int>, (indicating number of \"helpful votes\")\n",
    "#    <int>  (indicating total number of votes)\n",
    "#  ],\n",
    "#  \"reviewText\": \"<string>\",\n",
    "#  \"overall\": <int>,\n",
    "#  \"summary\": \"<string>\",\n",
    "#  \"unixReviewTime\": <int>,\n",
    "#  \"reviewTime\": \"<string>\"\n",
    "# }\n",
    "# \n",
    "# We are specifically interested in the fields \"helpful\" and \"reviewText\"\n",
    "#\n",
    "\n",
    "def label_data(input_data):\n",
    "    labeled_data = []\n",
    "    HELPFUL_LABEL = \"__label__1\"\n",
    "    UNHELPFUL_LABEL = \"__label__2\"\n",
    "     \n",
    "    for l in open(input_data, 'r'):\n",
    "        l_object = json.loads(l)\n",
    "        helpful_votes = float(l_object['helpful'][0])\n",
    "        total_votes = l_object['helpful'][1]\n",
    "        reviewText = l_object['reviewText']\n",
    "        if total_votes != 0:\n",
    "            if helpful_votes / total_votes > .5:\n",
    "                labeled_data.append(\" \".join([HELPFUL_LABEL, reviewText]))\n",
    "            elif helpful_votes / total_votes < .5:\n",
    "                labeled_data.append(\" \".join([UNHELPFUL_LABEL, reviewText]))\n",
    "          \n",
    "    return labeled_data\n",
    "\n",
    "\n",
    "# Labeled data is a list of sentences, starting with the label defined in label_data. \n",
    "\n",
    "def split_sentences(labeled_data):\n",
    "    new_split_sentences = []\n",
    "    for d in labeled_data:\n",
    "        label = d.split()[0]        \n",
    "        sentences = \" \".join(d.split()[1:]).split(\".\") # Initially split to separate label, then separate sentences\n",
    "        for s in sentences:\n",
    "            if s: # Make sure sentences isn't empty. Common w/ \"...\"\n",
    "                new_split_sentences.append(\" \".join([label, s]))\n",
    "    return new_split_sentences\n",
    "\n",
    "def write_data(data, train_path, test_path, proportion):\n",
    "    border_index = int(proportion * len(data))\n",
    "    train_f = open(train_path, 'w')\n",
    "    test_f = open(test_path, 'w')\n",
    "    index = 0\n",
    "    for d in data:\n",
    "        if index < border_index:\n",
    "            train_f.write(d + '\\n')\n",
    "        else:\n",
    "            test_f.write(d + '\\n')\n",
    "        index += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unzipped_path = unzip_data('Toys_and_Games_5.json.zip')\n",
    "    labeled_data = label_data(unzipped_path)\n",
    "    new_split_sentence_data = split_sentences(labeled_data)\n",
    "    write_data(new_split_sentence_data, 'data/processing/output/train/hello_blaze_train_scikit', 'data/processing/output/test/hello_blaze_test_scikit', .9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085b93a",
   "metadata": {},
   "source": [
    "## Exercise: Upload unprocessed data to s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e0d71",
   "metadata": {},
   "source": [
    "No more local preprocessing! Upload the **raw zipped** Toys_and_Games dataset to s3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd83d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mk-aws-ml-engineer-nanodegree-2022/exercises/processing-job/preprocessed-data\n"
     ]
    }
   ],
   "source": [
    "# Todo\n",
    "s3_bucket = \"mk-aws-ml-engineer-nanodegree-2022\"\n",
    "s3_prefix = \"exercises/processing-job\"\n",
    "file_name = \"preprocessed-data\"\n",
    "\n",
    "def upload_file_to_s3(file_name, s3_prefix):\n",
    "    object_name = os.path.join(s3_prefix, file_name)\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, s3_bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "\n",
    "source_path = \"/\".join([s3_bucket, s3_prefix, file_name])\n",
    "print(source_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18ed20",
   "metadata": {},
   "source": [
    "## Exercise: Launch a processing job through the SciKitLearn interface. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfef0aef",
   "metadata": {},
   "source": [
    "We'll be utilizing the SKLearnProcessor object from SageMaker to launch a processing job. Here is some information you'll need to complete the exercise: \n",
    "\n",
    "* You will need to use the SKLearnProcessor object. \n",
    "* You will need 1 instance of ml.m5.large. You can specify this programatically. \n",
    "* You will need an execution role.  \n",
    "\n",
    "* You will need to call the \"run\" method on the SKLearnProcessor object.\n",
    "> * You will need to specify the preprocessing code\n",
    "> * the S3 path of the unprocessed data\n",
    "> * a 'local' directory path for the input to be downloaded into\n",
    "> * 'local' directory paths for where you expect the output to be.\n",
    "\n",
    "you will need to make use of the ProcessingInput and ProcessingOutput features. Review the preprocessing code for where the output is going to go, and where it expects the input to come from.  \n",
    "* It is highly recommended that you consult the documentation to help you implement this. https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html\n",
    "\n",
    "Remember that, conceptually, you are creating a server that our code will be run from. This server will download data, execute code that we specify, and upload data to s3. \n",
    "\n",
    "If done successfully, you should see a processing job launch in the SageMaker console. To see it, go to the \"processing\" drop-down menu on the left-hand side and select \"processing jobs.\" Wait until the job is finished. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d97d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name voclabs to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2022-04-18-08-03-39-214\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://mk-aws-ml-engineer-nanodegree-2022/exercises/processing-job/raw-data/Toys_and_Games_5.json.zip', 'LocalPath': 'data/processing/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-419056005463/sagemaker-scikit-learn-2022-04-18-08-03-39-214/input/code/HelloBlazePreprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output-1', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-419056005463/sagemaker-scikit-learn-2022-04-18-08-03-39-214/output/output-1', 'LocalPath': 'data/processing/output/train/hello_blaze_train_scikit', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-2', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-419056005463/sagemaker-scikit-learn-2022-04-18-08-03-39-214/output/output-2', 'LocalPath': 'data/processing/output/test/hello_blaze_test_scikit', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateProcessingJob operation: Invalid LocalPath \"data/processing/\" for ProcessingInput \"input-1\". Please supply an absolute path for LocalPath that begins with \"/opt/ml/processing\", such as \"/opt/ml/processing/input\" or \"/opt/ml/processing/output\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m sklearn_processor \u001b[38;5;241m=\u001b[39m SKLearnProcessor(framework_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.20.0\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                      role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[0;32m     13\u001b[0m                                      instance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml.m5.large\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m                                      instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m                                     )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Start a run job. You will pass in as parameters the local location of the processing code, \u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# a processing input object, two processing output objects. The paths that you pass in here are directories, \u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# not the files themselves. Check the preprocessing code for a hint about what these directories should be. \u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43msklearn_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHelloBlazePreprocess.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# preprocessing code\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mProcessingInput\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://mk-aws-ml-engineer-nanodegree-2022/exercises/processing-job/raw-data/Toys_and_Games_5.json.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the S3 path of the unprocessed data\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/processing/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# a 'local' directory path for the input to be downloaded into\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                      \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mProcessingOutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/processing/output/train/hello_blaze_train_scikit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m# a 'local' directory path for where you expect the output for train data to be\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mProcessingOutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/processing/output/test/hello_blaze_test_scikit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\aws-ml-engineer-nanodegree\\aws-ml-engineer-venv\\lib\\site-packages\\sagemaker\\processing.py:551\u001b[0m, in \u001b[0;36mScriptProcessor.run\u001b[1;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;124;03m\"\"\"Runs a processing job.\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03m        * `TrialComponentDisplayName` is used for display in Studio.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m normalized_inputs, normalized_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_args(\n\u001b[0;32m    543\u001b[0m     job_name\u001b[38;5;241m=\u001b[39mjob_name,\n\u001b[0;32m    544\u001b[0m     arguments\u001b[38;5;241m=\u001b[39marguments,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    548\u001b[0m     kms_key\u001b[38;5;241m=\u001b[39mkms_key,\n\u001b[0;32m    549\u001b[0m )\n\u001b[1;32m--> 551\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_job \u001b[38;5;241m=\u001b[39m \u001b[43mProcessingJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalized_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalized_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_job)\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n",
      "File \u001b[1;32m~\\PycharmProjects\\aws-ml-engineer-nanodegree\\aws-ml-engineer-venv\\lib\\site-packages\\sagemaker\\processing.py:775\u001b[0m, in \u001b[0;36mProcessingJob.start_new\u001b[1;34m(cls, processor, inputs, outputs, experiment_config)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, process_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_config\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# Call sagemaker_session.process using the arguments dictionary.\u001b[39;00m\n\u001b[1;32m--> 775\u001b[0m processor\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mprocess(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprocess_args)\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    778\u001b[0m     processor\u001b[38;5;241m.\u001b[39msagemaker_session,\n\u001b[0;32m    779\u001b[0m     processor\u001b[38;5;241m.\u001b[39m_current_job_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    782\u001b[0m     processor\u001b[38;5;241m.\u001b[39moutput_kms_key,\n\u001b[0;32m    783\u001b[0m )\n",
      "File \u001b[1;32m~\\PycharmProjects\\aws-ml-engineer-nanodegree\\aws-ml-engineer-venv\\lib\\site-packages\\sagemaker\\session.py:917\u001b[0m, in \u001b[0;36mSession.process\u001b[1;34m(self, inputs, output_config, job_name, resources, stopping_condition, app_specification, environment, network_config, role_arn, tags, experiment_config)\u001b[0m\n\u001b[0;32m    915\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating processing-job with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[0;32m    916\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(process_request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m--> 917\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_processing_job(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprocess_request)\n",
      "File \u001b[1;32m~\\PycharmProjects\\aws-ml-engineer-nanodegree\\aws-ml-engineer-venv\\lib\\site-packages\\botocore\\client.py:415\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m py_operation_name)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\aws-ml-engineer-nanodegree\\aws-ml-engineer-venv\\lib\\site-packages\\botocore\\client.py:745\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    743\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    744\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateProcessingJob operation: Invalid LocalPath \"data/processing/\" for ProcessingInput \"input-1\". Please supply an absolute path for LocalPath that begins with \"/opt/ml/processing\", such as \"/opt/ml/processing/input\" or \"/opt/ml/processing/output\"."
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Get role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# Create an SKLearnProcessor. Set framework_version='0.20.0'.\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.large',\n",
    "                                     instance_count=1\n",
    "                                    )\n",
    "\n",
    "# Start a run job. You will pass in as parameters the local location of the processing code, \n",
    "# a processing input object, two processing output objects. The paths that you pass in here are directories, \n",
    "# not the files themselves. Check the preprocessing code for a hint about what these directories should be. \n",
    "\n",
    "sklearn_processor.run(code= 'HelloBlazePreprocess.py', # preprocessing code\n",
    "                      inputs=[ProcessingInput(\n",
    "                          source = 's3://mk-aws-ml-engineer-nanodegree-2022/exercises/processing-job/raw-data/Toys_and_Games_5.json.zip', # the S3 path of the unprocessed data\n",
    "                          destination= 'data/processing/', # a 'local' directory path for the input to be downloaded into\n",
    "                      )],\n",
    "                      outputs=[ProcessingOutput(source= 'data/processing/output/train/hello_blaze_train_scikit'),# a 'local' directory path for where you expect the output for train data to be\n",
    "                               ProcessingOutput(source= 'data/processing/output/test/hello_blaze_test_scikit')]) # a 'local' directory path for where you expect the output for test data to be "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843700cf",
   "metadata": {},
   "source": [
    "## Exercise: Sanity Check & Reflection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53c1c8",
   "metadata": {},
   "source": [
    "If all goes well, processed data should have been uploaded to S3. If you're having trouble locating the uri, check the `jobs` attribute of the SKLearnProcessor object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211fc0b0",
   "metadata": {},
   "source": [
    "Download these datasets and compare them to the datasets that we locally processed. The exact sentences in the training & the test sets may vary depending on your implementation, but the same number of sentences should be present in each job, and there should be one label and one sentence per line.  \n",
    "\n",
    "\n",
    "Once you've confirmed that the data was accurately processed, take a step back and reflect on what you've done. You've created the individual components necessary to process data, train data, and perform inference on both individual instances of data and large datasets. What are we missing if we wanted to provide a live, continuous service? Keep this question in mind as we move on to designing workflows. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
